{
	"common.start": "Start",
	"common.stop": "Stop",
	"common.pause": "Pause",
	"common.resume": "Resume",
	"common.settings": "Settings",
	"common.test": "Test",
	"common.success": "Success",
	"common.error": "Error",
	"common.warning": "Warning",
	"common.info": "Info",
	"common.loading": "Loading",
	"common.enabled": "Enabled",
	"common.disabled": "Disabled",
	"common.save": "Save",
	"common.cancel": "Cancel",
	"common.edit": "Edit",
	"common.add": "Add",
	"common.delete": "Delete",
	"common.confirm": "Confirm",

	"plugin.name": "MeetingFlow AI",
	"plugin.description": "Professional enterprise meeting transcription and AI assistant,Real-time speech transcription and intelligent meeting workflow using OpenAI Realtime API.",
	"plugin.author": "XiaoYang",

	"statusbar.active": "Speech Transcription: Active",
	"statusbar.wait": "Speech Transcription: Wait",
	"statusbar.connReady": "Speech Transcription: ConnReady",
	"statusbar.audioReady": "Speech Transcription: AudioReady",
	"statusbar.paused": "Speech Transcription: Paused",
	"statusbar.detecting": "Speech Transcription: Detecting Speech (VAD)",
	"statusbar.processing": "Speech Transcription: Processing",
	"statusbar.transcribing": "Speech Transcription: Transcribing",
	"statusbar.connecting": "Speech Transcription: Connecting",
	"statusbar.ready": "Ready",

	"command.startTranscription": "üéôÔ∏è Start Speech Transcription",
	"command.stopTranscription": "‚èπÔ∏è Stop Speech Transcription",
	"command.pauseTranscription": "‚è∏Ô∏è Pause Speech Transcription",
	"command.toggleAiSidebar": "ü§ñ Toggle AI Assistant Sidebar",
	"command.newAiChat": "üí¨ New AI Chat",

	"controlpanel.title": "üéôÔ∏è Speech Transcription Control Panel",
	"controlpanel.start": "üéôÔ∏è Start Speech Transcription",
	"controlpanel.pause": "‚è∏Ô∏è Pause Speech Transcription",
	"controlpanel.resume": "‚ñ∂Ô∏è Resume Speech Transcription",
	"controlpanel.stop": "‚èπÔ∏è Stop Speech Transcription",
	"controlpanel.ai": "ü§ñ AI Meeting Assistant",
	"controlpanel.opened": "Control panel opened",
	"controlpanel.closed": "Control panel closed",
	"controlpanel.failed": "Failed to open control panel",

	"notice.transcription.started": "üéôÔ∏è Speech transcription started",
	"notice.transcription.stopped": "‚èπÔ∏è Speech transcription stopped",
	"notice.transcription.paused": "‚è∏Ô∏è Speech transcription paused",
	"notice.transcription.resumed": "‚ñ∂Ô∏è Speech transcription resumed",
	"notice.transcription.failed": "‚ùå Failed to start speech transcription: {{error}}",
	"notice.transcription.notActive": "‚ö†Ô∏è Speech transcription is not active",
	"notice.transcription.insertFailed": "‚ö†Ô∏è Cannot insert transcription text: no active Markdown editor",
	"notice.websocket.error": "‚ùå WebSocket error: {{error}}",
	"notice.websocket.lost": "üîÑ WebSocket connection lost, reconnecting...",
	"notice.websocket.reconnecting": "üîÑ WebSocket reconnecting...",
	"notice.websocket.reconnected": "üîÑ WebSocket reconnected, transcription resumed",
	"notice.websocket.reconnectFailed": "‚ùå WebSocket reconnection failed, please check network connection",
	"notice.ai.opened": "AI assistant opened",
	"notice.ai.alreadyOpen": "AI assistant is already open, expand the sidebar to view.",
	"notice.ai.failed": "Error toggling AI assistant: {{error}}",
	"notice.ai.chatStarted": "New AI chat started",
	"notice.connection.testSuccess": "‚úÖ AI API connection test successful",
	"notice.connection.testFailed": "‚ùå AI API connection test failed, please check configuration",

	"settings.speech.title": "üéôÔ∏è Speech Transcription Settings",
	"settings.speech.apiEndpoint": "API Endpoint",
	"settings.speech.apiEndpoint.desc": "WebSocket endpoint for real-time speech transcription API",
	"settings.speech.apiKey": "API Key",
	"settings.speech.apiKey.desc": "API key for authentication (optional if using ephemeral tokens)",
	"settings.speech.model": "Model",
	"settings.speech.model.desc": "Speech recognition model to use",
	"settings.speech.language": "Language",
	"settings.speech.language.desc": "Language for speech recognition (ISO 639-1 code)",
	"settings.speech.audioFormat": "Audio Format",
	"settings.speech.audioFormat.desc": "Audio format for transmission (PCM16: 16kHz, PCM48: 48kHz)",
	"settings.speech.sampleRate": "Sample Rate",
	"settings.speech.sampleRate.desc": "Audio sample rate (automatically set based on audio format)",
	"settings.speech.channels": "Audio Channels",
	"settings.speech.channels.desc": "Number of audio channels (1 for mono, 2 for stereo)",
	"settings.speech.vadSensitivity": "Voice Activity Detection Sensitivity",
	"settings.speech.vadSensitivity.desc": "Adjust sensitivity for voice detection (0.0 = most sensitive, 1.0 = least sensitive)",
	"settings.speech.maxDuration": "Maximum Audio Duration",
	"settings.speech.maxDuration.desc": "Maximum duration in seconds before forcing audio commit (fallback for servers without VAD)",
	"settings.speech.instructions": "To use this plugin, configure your API endpoint and start transcription using the squirrel ribbon icon or commands.",
	"settings.speech.formatInstructions": "PCM16 (16kHz): Lower quality, smaller file size, compatible with most systems. PCM48 (48kHz): Higher quality, larger file size, recommended for better transcription accuracy.",
	"settings.speech.vadInstructions": "This plugin supports both server-side VAD and fallback maximum duration protection for servers without VAD capability.",
	"settings.speech.keyboardShortcuts": "‚å®Ô∏è Shortcuts: Ctrl+F9 (Start), Ctrl+F10 (Stop)",

	"settings.ai.title": "ü§ñ AI Meeting Assistant Settings",
	"settings.ai.enableSidebar": "Enable AI Sidebar",
	"settings.ai.enableSidebar.desc": "Show AI meeting assistant in right sidebar",
	"settings.ai.apiEndpoint": "AI API Endpoint",
	"settings.ai.apiEndpoint.desc": "OpenAI-compatible API endpoint",
	"settings.ai.apiKey": "AI API Key",
	"settings.ai.apiKey.desc": "API key for AI service",
	"settings.ai.model": "AI Model",
	"settings.ai.model.desc": "AI model to use",
	"settings.ai.maxHistory": "Max History Items",
	"settings.ai.maxHistory.desc": "Maximum number of history items to save",
	"settings.ai.maxConversationHistory": "Conversation History Limit",
	"settings.ai.maxConversationHistory.desc": "Number of history messages to retain in AI assistant sessions (oldest messages will be automatically deleted when limit is exceeded)",
	"settings.ai.testConnection": "Test AI Connection",
	"settings.ai.testConnection.desc": "Click to test if AI API connection is working properly",

	"settings.commands.title": "Slash Commands Configuration",
	"settings.commands.aliasInfo": "üí° Built-in command aliases:",
	"settings.commands.addCustom": "Add Custom Command",
	"settings.commands.addCustom.desc": "Create new slash command",
	"settings.commands.tip": "üí° Tip: After configuring AI API, use /summary to start summarizing meeting content, or use /translate to translate text.",
	"settings.commands.builtIn": "Built-in Commands",
	"settings.commands.custom": "Custom Commands",

	"command.summary.name": "Summary",
	"command.translate.name": "Translate",
	"command.rewrite.name": "Rewrite",
	"command.actionItems.name": "Action Items",
	"command.clear.name": "Clear Chat",
	"command.help.name": "Help",

	"command.edit.title": "Edit Command",
	"command.edit.addTitle": "Add Command",
	"command.edit.name": "Command Name:",
	"command.edit.prompt": "Prompt:",
	"command.edit.alias": "Command Alias (Optional):",
	"command.edit.alias.placeholder": "e.g.: su (for summary command)",
	"command.edit.enabled": "Enable this command:",
	"command.edit.tip": "Tip: Use {context} as a placeholder for content in prompts",
	"command.edit.emptyName": "Please enter command name",
	"command.edit.emptyPrompt": "Please enter prompt",
	"command.edit.invalidAlias": "Alias can only contain letters, numbers, and hyphens",
	"command.edit.exists": "Command already exists, please use a different name",
	"command.edit.added": "Custom command added",
	"settings.commands.promptDesc": "Command prompt: {{prompt}}...",
	"settings.commands.alias": "Alias: /{{alias}}",
	"placeholder.apiEndpoint": "wss://your-api-server/v1/realtime",
	"placeholder.apiKey": "Enter your API key",
	"placeholder.model": "whisper-1",
	"placeholder.language": "en",
	"placeholder.channels": "1",
	"placeholder.vadSensitivity": "0.3",
	"placeholder.maxDuration": "30",
	"placeholder.aiApiEndpoint": "https://api.openai.com/v1/chat/completions",
	"placeholder.aiApiKey": "Enter your AI API key",
	"placeholder.aiModel": "gpt-3.5-turbo",
	"commands.defaultPrompts.summary": "## Role\nMeeting Minutes Expert\n\n### Notes\nRole design should focus on the completeness and clarity of meeting minutes.\nExpert design should help users efficiently organize and distill meeting content.\nUse structured and organized approach to present meeting minutes.\nPersonality Type Indicator\nISTJ (Introverted Sensing Thinking Judging)\n\n## Background\nMeeting Minutes Expert is dedicated to helping users organize and distill meeting content, outputting complete and clear meeting minutes including meeting content, key points, meeting summary, and action items.\n\n## Constraints\nMust ensure the accuracy and objectivity of meeting minutes.\nShould arrange the structure of meeting minutes reasonably to make them easy to understand and reference.\n\n## Definition\nMeeting Minutes - A document that records meeting content, discussion points, decisions, and action items.\n\n## Goals\nOrganize and distill meeting content to form complete meeting minutes.\nHighlight the core points and decisions of the meeting.\nClarify meeting summary and action items for follow-up.\n\n## Skills\nInformation organization and distillation capabilities.\nStructured thinking and document formatting abilities.\nAttention to detail to ensure information accuracy.\n\n## Tone\nObjective, accurate.\nClear, organized.\n\n## Values\nPursue efficient and accurate meeting content organization.\nValue the key role of meeting minutes in meeting management and subsequent actions.\n\n## Workflow\nStep 1: Receive and read meeting records and related materials.\nStep 2: Identify and distill the main content and core points of the meeting.\nStep 3: Based on meeting discussions, summarize the main decisions and conclusions.\nStep 4: Clarify action items generated from the meeting, including responsible persons, deadlines, etc.\nStep 5: Format meeting minutes according to standard format, ensuring clear structure and complete content.\nStep 6: Review and proofread meeting minutes to ensure no omissions or errors.\nStep 7: Submit organized meeting minutes to users and make necessary modifications based on feedback.\n\n---\n\nBelow is the meeting record content:\n{context}\n",
	"commands.defaultPrompts.translate": "Please translate the following content to Chinese:\n\n{context}",
	"commands.defaultPrompts.rewrite": "Please rewrite the following content to make it clearer and more organized:\n\n{context}",
	"commands.defaultPrompts.actionItems": "Please extract all action items from the following meeting content, including responsible persons and deadlines (if possible):\n\n{context}",
	"commands.defaultPrompts.generic": "Please process the following content:\n\n{context}",
	"buttons.startTranscription": "üéôÔ∏è Start Speech Transcription",
	"buttons.pauseTranscription": "‚è∏Ô∏è Pause Speech Transcription",
	"buttons.resumeTranscription": "‚ñ∂Ô∏è Resume Speech Transcription",
	"buttons.stopTranscription": "‚èπÔ∏è Stop Speech Transcription",
	"buttons.aiAssistant": "ü§ñ AI Meeting Assistant",

	"command.help.summary": "Summarize meeting content (auto-references current content) (alias: /su)",
	"command.help.translate": "Translate content (e.g., /translate zh-CN \"hello\") or /translate zh-CN (auto-references current)) (alias: /tr)",
	"command.help.rewrite": "Rewrite content to make it clearer (auto-references current content) (alias: /rw)",
	"command.help.actionItems": "Extract action items (auto-references current content) (alias: /ai)",
	"command.help.new": "Start new conversation",
	"command.help.clear": "Clear current conversation (alias: /cl)",
	"command.help.help": "Show help information (alias: /h)",
	"command.help.tip": "üí° Tip: Content after commands automatically references the current view, or you can specify specific content."
}